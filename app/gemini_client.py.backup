from __future__ import annotations

import logging
import json
import re
from typing import List, Dict, Any, Optional

import requests
from requests import RequestException

from .config import config
from . import state
from .gemini_test_generator_new import generate_question_tests_new


class GeminiError(RuntimeError):
    """Raised when the Gemini API returns an unexpected response."""


class GeminiClient:
    API_URL_TEMPLATE = (
        "https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
    )

    def __init__(self, api_key: str | None = None, model: str | None = None) -> None:
        self.api_key = api_key or config.GEMINI_API_KEY
        self.model = model or config.GEMINI_MODEL
        self.phase_model = config.GEMINI_PHASE_MODEL or self.model
        self.test_model = config.GEMINI_TEST_MODEL or self.model
        if not self.api_key:
            raise ValueError(
                "Gemini API key is not configured. Set the GEMINI_API_KEY environment variable."
            )

    def generate_interview_reply(
        self,
        conversation: List[Dict[str, Any]],
        resume_text: str | None,
        user_message: str,
        temperature: float = 0.7,
    ) -> str:
        """
        Sends the conversation history and the latest user message to Gemini and returns the reply text.

        Args:
            conversation: Existing conversation history formatted for the Gemini API.
            resume_text: Optional resume text to ground the interview context.
            user_message: Latest user utterance to append to the conversation.
            temperature: Sampling temperature for response creativity.
        """
        payload = self._build_payload(conversation, resume_text, user_message, temperature)
        response = requests.post(
            self.API_URL_TEMPLATE.format(model=self.model),
            params={"key": self.api_key},
            json=payload,
            timeout=30,
        )
        if response.status_code != 200:
            logging.error(
                "Gemini API error: status=%s body=%s",
                response.status_code,
                response.text,
            )
            raise GeminiError(f"Gemini API error {response.status_code}: {response.text}")

        data = response.json()
        try:
            parts = data["candidates"][0]["content"]["parts"]
            combined_text = " ".join(part.get("text", "") for part in parts if "text" in part).strip()
            if not combined_text:
                raise KeyError("Empty response text")
            return combined_text
        except (KeyError, IndexError) as exc:
            logging.error("Unexpected Gemini API payload: %s", data)
            raise GeminiError("Gemini API returned an unexpected payload") from exc

    def _build_payload(
        self,
        conversation: List[Dict[str, Any]],
        resume_text: str | None,
        user_message: str,
        temperature: float,
    ) -> Dict[str, Any]:
        system_prompt = (
            "You are an experienced senior engineer conducting a LIVE VOICE mock technical interview. "
            "This is a natural, back-and-forth CONVERSATION, not a written exchange.\n\n"
            "CRITICAL CONVERSATION RULES:\n"
            "- Keep responses SHORT and NATURAL - like how people actually talk (1-3 sentences usually)\n"
            "- Vary your response length based on context: sometimes just 'Got it', 'Makes sense', 'Tell me more', "
            "sometimes a follow-up question, sometimes detailed feedback\n"
            "- ANALYZE the conversation history and user's last message to determine the appropriate response type:\n"
            "  * Short acknowledgment (e.g., 'Okay', 'I see', 'Right')\n"
            "  * Brief follow-up question (e.g., 'What about error handling?')\n"
            "  * Deeper probe (e.g., 'Walk me through your approach to...')\n"
            "  * Constructive feedback (when they finish explaining something)\n"
            "  * Topic switch (when current topic is exhausted)\n"
            "- Speak like a human in conversation: use contractions (I'm, you're, that's), casual phrasing, "
            "natural pauses indicated by punctuation\n"
            "- NEVER write essay-style responses - you're SPEAKING, not writing\n"
            "- Listen actively: reference what they just said, build on it naturally\n"
            "- Don't explain everything at once - let the conversation flow organically\n"
            "- Ask ONE question at a time, not multiple\n"
            "- Balance between being supportive and challenging them appropriately\n\n"
            "CRITICAL - TEXT-TO-SPEECH OUTPUT:\n"
            "- Your output will be converted to SPEECH by a TTS system\n"
            "- NEVER use markdown symbols: NO asterisks (*), NO hashtags (#), NO underscores (_)\n"
            "- NEVER use formatting: NO **bold**, NO *italics*, NO `code blocks`\n"
            "- NEVER use filler words like 'um', 'uh', 'hmm', 'well', 'so'\n"
            "- Speak clearly and directly - write EXACTLY what should be spoken out loud\n"
            "- For code or technical terms, just say them plainly"
        )
        if resume_text:
            system_prompt += (
                "\nThe candidate resume you have is below. Use it to tailor your questions "
                "and feedback. Focus on relevant technologies, accomplishments, and gaps.\n"
                f"Resume:\n{resume_text}\n"
            )

        # Clone conversation to avoid mutating caller data
        conversation_payload = list(conversation)
        conversation_payload.append(
            {
                "role": "user",
                "parts": [
                    {
                        "text": user_message,
                    }
                ],
            }
        )

        payload: Dict[str, Any] = {
            "systemInstruction": {
                "role": "system",
                "parts": [
                    {
                        "text": system_prompt,
                    }
                ],
            },
            "contents": conversation_payload,
            "generationConfig": {
                "temperature": temperature,
                "topP": 0.95,
                "topK": 40,
                "maxOutputTokens": 800,  # Increased to allow code responses
            },
        }
        return payload

    def generate_structured_interview_reply(
        self,
        session_id: str,
        conversation: List[Dict[str, Any]],
        resume_text: str | None,
        user_message: str,
        current_code: str = "",
        code_changed: bool = False,
        temperature: float = 0.7,
    ) -> str:
        """
        Generate reply for structured interview with phase awareness.

        Args:
            session_id: Session identifier
            conversation: Existing conversation history
            resume_text: Resume text for context
            user_message: Latest user utterance
            current_code: Current code in editor
            code_changed: Whether code changed recently
            temperature: Sampling temperature
        """
        interview_state = state.get_interview_state(session_id)
        if not interview_state:
            # Fallback to regular interview if no structured state
            return self.generate_interview_reply(conversation, resume_text, user_message, temperature)

        payload = self._build_structured_payload(
            session_id,
            interview_state,
            conversation,
            resume_text,
            user_message,
            current_code,
            code_changed,
            temperature,
        )

        # Debug logging
        system_prompt = payload.get("systemInstruction", {}).get("parts", [{}])[0].get("text", "")
        logging.info(f"[GEMINI DEBUG] Current code length: {len(current_code)}")
        if current_code:
            logging.info(f"[GEMINI DEBUG] Code is included in prompt: {bool('CURRENT CODE IN EDITOR' in system_prompt)}")
        logging.info(f"[GEMINI DEBUG] System prompt length: {len(system_prompt)}")

        response = requests.post(
            self.API_URL_TEMPLATE.format(model=self.model),
            params={"key": self.api_key},
            json=payload,
            timeout=30,
        )

        if response.status_code != 200:
            logging.error(
                "Gemini API error: status=%s body=%s",
                response.status_code,
                response.text,
            )
            raise GeminiError(f"Gemini API error {response.status_code}: {response.text}")

        data = response.json()
        try:
            parts = data["candidates"][0]["content"]["parts"]
            combined_text = " ".join(part.get("text", "") for part in parts if "text" in part).strip()
            if not combined_text:
                raise KeyError("Empty response text")
            return combined_text
        except (KeyError, IndexError) as exc:
            logging.error("Unexpected Gemini API payload: %s", data)
            raise GeminiError("Gemini API returned an unexpected payload") from exc

    def generate_interview_report(
        self,
        mode: str,
        language: str,
        conversation: List[Dict[str, Any]],
        current_code: str,
        code_snapshots: List[Dict[str, Any]],
        problem_presented: bool,
    ) -> Dict[str, Any]:
        """Generate a structured feedback report for the completed interview."""
        system_prompt = (
            "You are a senior engineering interviewer writing a concise evaluation report. "
            "Assess the candidate like a real SDE interview. "
            "Return STRICT JSON only, no extra commentary."
        )

        rubric_details = {
            "problem_solving": "How well they structured the approach, validated assumptions, and decomposed the problem.",
            "technical_depth": "Quality of algorithm/data structure reasoning and trade-off analysis.",
            "coding_correctness": "Correctness of implementation vs. requirements.",
            "edge_cases": "Coverage of tricky inputs and boundary conditions.",
            "efficiency": "Time/space complexity choices and optimization awareness.",
            "communication": "Clarity, structure, and collaboration throughout.",
            "code_quality": "Readability, naming, organization, and maintainability.",
        }

        # For report generation, include significant conversation history but not everything
        # to avoid overwhelming the context window. 40 turns should capture key moments
        # while leaving room for detailed output.
        max_conversation_turns = min(40, len(conversation) if conversation else 0)

        context = {
            "mode": mode,
            "language": language,
            "problem_presented": problem_presented,
            "conversation_summary": self._format_conversation_snippet(
                conversation,
                max_turns=max_conversation_turns,
            ),
            "total_conversation_turns": len(conversation) if conversation else 0,
            "current_code": current_code or "[empty]",
            "code_snapshot_count": len(code_snapshots),
        }

        instructions = (
            "Return JSON with EXACTLY this structure (no additional fields):\n"
            "{\n"
            '  "overall_score": number 1-5,\n'
            '  "recommendation": "strong_hire" | "hire" | "lean_hire" | "lean_no_hire" | "no_hire",\n'
            '  "summary": "Brief 2-sentence evaluation",\n'
            '  "category_scores": {\n'
            '     "problem_solving": 1-5,\n'
            '     "technical_depth": 1-5,\n'
            '     "coding_correctness": 1-5,\n'
            '     "edge_cases": 1-5,\n'
            '     "efficiency": 1-5,\n'
            '     "communication": 1-5,\n'
            '     "code_quality": 1-5\n'
            "  },\n"
            '  "strengths": ["concise point 1", "concise point 2", "concise point 3"],\n'
            '  "improvements": ["concise point 1", "concise point 2", "concise point 3"],\n'
            '  "notable_moments": ["brief moment 1", "brief moment 2", "brief moment 3"]\n'
            "}\n\n"
            "IMPORTANT:\n"
            "- Output ONLY the JSON structure above with NO additional fields\n"
            "- Do NOT add explanations for category scores (scores are self-explanatory)\n"
            "- Keep each strength/improvement/moment to ONE sentence max\n"
            "- Be specific but concise\n"
            "- Output raw JSON only (no markdown, no code fences, no commentary)"
        )

        payload = {
            "systemInstruction": {
                "role": "system",
                "parts": [{"text": system_prompt}],
            },
            "contents": [
                {
                    "role": "user",
                    "parts": [
                        {
                            "text": instructions
                            + "\n\nCONTEXT:\n"
                            + json.dumps(context, ensure_ascii=False),
                        }
                    ],
                }
            ],
            "generationConfig": {
                "temperature": 0.2,
                "topP": 0.9,
                "topK": 40,
                "maxOutputTokens": 2048,
                "responseMimeType": "application/json",
            },
        }

        response = requests.post(
            self.API_URL_TEMPLATE.format(model=self.model),
            params={"key": self.api_key},
            json=payload,
            timeout=30,
        )
        if response.status_code != 200:
            logging.error(
                "Gemini API error: status=%s body=%s",
                response.status_code,
                response.text,
            )
            raise GeminiError(f"Gemini API error {response.status_code}: {response.text}")

        data = response.json()

        # Check if response was truncated due to token limit
        finish_reason = data.get("candidates", [{}])[0].get("finishReason", "")
        if finish_reason == "MAX_TOKENS":
            logging.warning(
                "Report generation hit MAX_TOKENS limit. Retrying with higher limit. "
                "Original response: %s",
                data
            )
            # Retry with higher token limit
            payload["generationConfig"]["maxOutputTokens"] = 3072
            response = requests.post(
                self.API_URL_TEMPLATE.format(model=self.model),
                params={"key": self.api_key},
                json=payload,
                timeout=30,
            )
            if response.status_code != 200:
                logging.error(
                    "Gemini API error on retry: status=%s body=%s",
                    response.status_code,
                    response.text,
                )
                raise GeminiError(f"Gemini API error {response.status_code}: {response.text}")
            data = response.json()
            finish_reason = data.get("candidates", [{}])[0].get("finishReason", "")
            if finish_reason == "MAX_TOKENS":
                logging.error(
                    "Report generation still hitting MAX_TOKENS even with 3072 limit. "
                    "Response: %s",
                    data
                )

        try:
            parts = data["candidates"][0]["content"]["parts"]
            combined_text = " ".join(part.get("text", "") for part in parts if "text" in part).strip()
            if not combined_text:
                raise KeyError("Empty response text")
            report = self._parse_json_from_text(combined_text)
        except (KeyError, IndexError, json.JSONDecodeError) as exc:
            logging.error("Unexpected Gemini report payload: %s", data)
            if finish_reason == "MAX_TOKENS":
                raise GeminiError(
                    "Report generation exceeded token limit. The interview may be too long. "
                    "Please try ending the interview earlier or contact support."
                ) from exc
            raise GeminiError("Gemini API returned an invalid report payload") from exc

        report["rubric_details"] = rubric_details
        return report

    def _parse_json_from_text(self, text: str) -> Dict[str, Any]:
        """Parse JSON from text, handling markdown code fences and extra whitespace."""
        cleaned = text.strip()
        # Remove markdown code fences if present
        if cleaned.startswith("```"):
            cleaned = re.sub(r"^```\w*\n?|```$", "", cleaned, flags=re.DOTALL).strip()
        # Extract JSON object between first { and last }
        start = cleaned.find("{")
        end = cleaned.rfind("}")
        if start != -1 and end != -1 and end > start:
            cleaned = cleaned[start:end + 1]
        return json.loads(cleaned)

    def generate_question_tests(self, question_title: str) -> Dict[str, Any]:
        """Generate test cases by having Gemini create solution code and inputs, then executing to get outputs."""
        print(f"[GEMINI] Generating tests for: {question_title}")
        print(f"[GEMINI] Using model: gemini-3-flash-preview")
        print(f"[GEMINI] API key configured: {'Yes' if self.api_key else 'No'}")
        if not question_title:
            raise ValueError("Question title is required for test generation.")

        system_prompt = (
            "You generate coding interview test cases for LeetCode-style problems.\n"
            "Return ONLY valid JSON, no markdown, no extra text.\n"
            "Return a single-line MINIFIED JSON with no extra whitespace or newlines.\n"
            "Use the following schema:\n"
            "{\n"
            '  "question_title": string,\n'
            '  "function_signatures": {\n'
            '    "python": {"function_name": string, "parameters": [{"name": string, "type": string}], "return_type": string},\n'
            '    "java": {"class_name": "Solution", "method_name": string, "parameters": [{"name": string, "type": string}], "return_type": string, "static": true},\n'
            '    "cpp": {"function_name": string, "parameters": [{"name": string, "type": string}], "return_type": string},\n'
            '    "c": {"function_name": string, "parameters": [{"name": string, "type": string, "size_param": string}], "return_type": string, "return_size_param": string}\n'
            "  },\n"
            '  "comparison": "exact" | "unordered",\n'
            '  "tests": [{"input": {param: value}, "output": value}]\n'
            "}\n\n"
            "Rules:\n"
            "- Generate exactly 10 tests.\n"
            "- Inputs must map to parameter names.\n"
            "- Types must be one of: int, bool, string, int[], string[], int[][], string[][].\n"
            "- Use LeetCode-standard naming: python snake_case, java/cpp camelCase.\n"
            "- For C, use the same type strings as above and include size_param for each array parameter and return_size_param for array returns.\n"
            "- Ensure outputs are deterministic.\n"
            "- Keep test inputs and outputs SMALL to limit JSON size:\n"
            "  * arrays length <= 6, strings length <= 8, matrices <= 4x4, small integers\n"
            "  * if outputs grow quickly (e.g., Pascal's triangle), use very small inputs\n"
            "- If you cannot fit the JSON, further shrink inputs and outputs.\n"
        )

        user_prompt = f"Question title: {question_title}"

        def _request_tests_sdk(max_output_tokens: int, compact: bool) -> Optional[Dict[str, Any]]:
            try:
                import google.generativeai as genai
            except ImportError:
                print(f"[GEMINI SDK] google.generativeai not available")
                return None

            compact_prompt = ""
            if compact:
                compact_prompt = (
                    "\nOutput must be fully valid JSON. If space is tight, "
                    "use the smallest possible inputs and outputs.\n"
                )

            try:
                genai.configure(api_key=self.api_key)

                # Configure safety settings to be more lenient for technical content
                safety_settings = {
                    "HARM_CATEGORY_HARASSMENT": "BLOCK_NONE",
                    "HARM_CATEGORY_HATE_SPEECH": "BLOCK_NONE",
                    "HARM_CATEGORY_SEXUALLY_EXPLICIT": "BLOCK_NONE",
                    "HARM_CATEGORY_DANGEROUS_CONTENT": "BLOCK_NONE",
                }

                model = genai.GenerativeModel(
                    self.test_model,
                    system_instruction=system_prompt,
                    safety_settings=safety_settings
                )
                generation_config = {
                    "temperature": 0.2,
                    "top_p": 0.9,
                    "top_k": 40,
                    "max_output_tokens": max_output_tokens,
                    "response_mime_type": "application/json",
                }
                print(f"[GEMINI SDK] Making request to {self.test_model}")
                response = model.generate_content(user_prompt + compact_prompt, generation_config=generation_config)
                print(f"[GEMINI SDK] Response received")
            except Exception as exc:
                print(f"[GEMINI SDK ERROR] {type(exc).__name__}: {exc}")
                logging.error("Gemini SDK test generation error: %s", exc)
                return None

            # Check if response was blocked
            try:
                if hasattr(response, 'candidates') and response.candidates:
                    candidate = response.candidates[0]
                    if hasattr(candidate, 'safety_ratings'):
                        print(f"[GEMINI SDK] Safety ratings: {candidate.safety_ratings}")
                    if hasattr(candidate, 'finish_reason'):
                        finish_reason = candidate.finish_reason
                        finish_reason_name = {
                            0: "UNSPECIFIED",
                            1: "STOP",
                            2: "MAX_TOKENS",
                            3: "SAFETY",
                            4: "RECITATION",
                            5: "OTHER"
                        }.get(finish_reason, f"UNKNOWN({finish_reason})")
                        print(f"[GEMINI SDK] Finish reason: {finish_reason_name}")

                        # If hit max tokens, don't try to parse, let retry with more tokens
                        if finish_reason == 2:  # MAX_TOKENS
                            print(f"[GEMINI SDK] Hit max tokens, will retry with more")
                            return None

                combined_text = (getattr(response, "text", "") or "").strip()
            except ValueError as e:
                # response.text accessor failed, likely blocked response
                print(f"[GEMINI SDK] Failed to access response.text: {e}")
                if hasattr(response, 'candidates') and response.candidates:
                    candidate = response.candidates[0]
                    print(f"[GEMINI SDK] Candidate safety_ratings: {getattr(candidate, 'safety_ratings', 'N/A')}")
                    finish_reason = getattr(candidate, 'finish_reason', 'N/A')
                    print(f"[GEMINI SDK] Candidate finish_reason: {finish_reason}")
                return None

            if not combined_text:
                print(f"[GEMINI SDK] No text in response")
                return None
            try:
                parsed = self._parse_json_from_text(combined_text)
                print(f"[GEMINI SDK] Successfully parsed JSON")
                return parsed
            except json.JSONDecodeError as e:
                print(f"[GEMINI SDK] JSON decode error: {e}")
                return None

        def _request_tests(max_output_tokens: int, compact: bool) -> Dict[str, Any]:
            compact_prompt = ""
            if compact:
                compact_prompt = (
                    "\nOutput must be fully valid JSON. If space is tight, "
                    "use the smallest possible inputs and outputs.\n"
                )
            payload = {
                "systemInstruction": {"role": "system", "parts": [{"text": system_prompt}]},
                "contents": [{"role": "user", "parts": [{"text": user_prompt + compact_prompt}]}],
                "generationConfig": {
                    "temperature": 0.2,
                    "topP": 0.9,
                    "topK": 40,
                    "maxOutputTokens": max_output_tokens,
                    "responseMimeType": "application/json",
                    # Removed thinkingConfig - gemini-2.5-pro requires thinking mode enabled
                },
                "safetySettings": [
                    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
                ],
            }

            print(f"[GEMINI REST] Making request to {self.test_model}")
            response = requests.post(
                self.API_URL_TEMPLATE.format(model=self.test_model),
                params={"key": self.api_key},
                json=payload,
                timeout=60,
            )
            print(f"[GEMINI REST] Response status: {response.status_code}")
            if response.status_code != 200:
                error_msg = response.text[:500]  # Truncate for readability
                print(f"[GEMINI REST ERROR] Status {response.status_code}: {error_msg}")
                logging.error(
                    "Gemini test generation error: status=%s body=%s",
                    response.status_code,
                    response.text,
                )
                raise GeminiError(f"Gemini test generation error {response.status_code}: {response.text}")

            data = response.json()
            try:
                candidate = data["candidates"][0]
                parts = candidate.get("content", {}).get("parts", [])
                combined_text = " ".join(part.get("text", "") for part in parts if "text" in part).strip()
                finish_reason = candidate.get("finishReason", "")
                print(f"[GEMINI REST] Finish reason: {finish_reason}")
            except (KeyError, IndexError) as exc:
                logging.error("Unexpected test generation payload: %s", data)
                raise GeminiError("Gemini returned invalid test case JSON") from exc

            if not combined_text:
                print(f"[GEMINI REST] No text in response")
                if finish_reason == "MAX_TOKENS":
                    print(f"[GEMINI REST] Hit max tokens, will retry with more")
                    raise GeminiError("Gemini hit token limit during test generation.")
                logging.error("Unexpected test generation payload: %s", data)
                raise GeminiError("Gemini returned invalid test case JSON")

            # Check if hit max tokens even with text (partial response)
            if finish_reason == "MAX_TOKENS":
                print(f"[GEMINI REST] Hit max tokens (partial response), will retry with more")
                raise GeminiError("Gemini hit token limit during test generation.")

            try:
                parsed = self._parse_json_from_text(combined_text)
                print(f"[GEMINI REST] Successfully parsed JSON")
                return parsed
            except json.JSONDecodeError as exc:
                print(f"[GEMINI REST] JSON decode error: {exc}")
                logging.error("Unexpected test generation payload: %s", data)
                raise GeminiError("Gemini returned invalid test case JSON") from exc

        parsed = None
        attempt_params = [
            (2400, False),
            (4096, False),
            (4096, True),
        ]

        for idx, (max_tokens, compact) in enumerate(attempt_params, 1):
            print(f"[GEMINI] Attempt {idx}/3: max_tokens={max_tokens}, compact={compact}")
            sdk_parsed = _request_tests_sdk(max_tokens, compact)
            if sdk_parsed:
                print(f"[GEMINI] SDK request succeeded on attempt {idx}")
                parsed = sdk_parsed
                break
            print(f"[GEMINI] SDK request failed, trying REST API")
            try:
                parsed = _request_tests(max_tokens, compact)
                print(f"[GEMINI] REST API request succeeded on attempt {idx}")
                break
            except GeminiError as exc:
                print(f"[GEMINI] REST API attempt {idx} failed: {exc}")
                if "token limit" not in str(exc).lower() and "invalid test case json" not in str(exc).lower():
                    print(f"[GEMINI] Non-retryable error, raising exception")
                    raise
                parsed = None

        if parsed is None:
            print(f"[GEMINI ERROR] All attempts failed")
            raise GeminiError("Gemini returned invalid test case JSON")

        tests = parsed.get("tests", [])
        if not isinstance(tests, list) or len(tests) != 10:
            raise GeminiError("Gemini test generation did not return exactly 10 tests.")

        return parsed

    def _build_structured_payload(
        self,
        session_id: str,
        interview_state: Dict[str, Any],
        conversation: List[Dict[str, Any]],
        resume_text: str | None,
        user_message: str,
        current_code: str,
        code_changed: bool,
        temperature: float,
    ) -> Dict[str, Any]:
        """Build payload with phase-aware prompting for structured interview"""

        current_phase = interview_state.get("current_phase", state.PHASE_INTRO)
        language = interview_state.get("language", "python")
        problem_presented = interview_state.get("problem_presented", False)
        mode = interview_state.get("mode", "full")
        company_context = interview_state.get("company_context")
        ood_question = interview_state.get("ood_question")
        coding_question = interview_state.get("coding_question")
        code_evaluation = state.get_code_evaluation(session_id)

        normalized_code = self._normalize_editor_code(current_code)

        # Calculate timing information
        time_in_phase = state.calculate_time_in_phase(session_id)
        total_time = state.calculate_total_time(session_id)
        silence_duration = state.calculate_silence_duration(session_id)
        code_idle_duration = state.calculate_code_idle_duration(session_id)

        # Build comprehensive system prompt
        system_prompt = self._build_phase_prompt(
            current_phase,
            language,
            resume_text,
            normalized_code,
            code_changed,
            problem_presented,
            time_in_phase,
            total_time,
            silence_duration,
            code_idle_duration,
            mode,
            company_context,
            ood_question,
            coding_question,
            code_evaluation,
        )

        # Build conversation payload
        conversation_payload = list(conversation)
        enriched_user_message = self._build_user_payload_with_editor_context(
            user_message=user_message,
            normalized_code=normalized_code,
        )
        conversation_payload.append(
            {
                "role": "user",
                "parts": [{"text": enriched_user_message}],
            }
        )

        payload: Dict[str, Any] = {
            "systemInstruction": {
                "role": "system",
                "parts": [{"text": system_prompt}],
            },
            "contents": conversation_payload,
            "generationConfig": {
                "temperature": temperature,
                "topP": 0.95,
                "topK": 40,
                "maxOutputTokens": 800,  # Increased to allow code responses
            },
        }
        return payload

    def decide_phase_transition(
        self,
        session_id: str,
        interview_state: Dict[str, Any],
        conversation: List[Dict[str, Any]],
        user_message: str,
        model_reply: str,
    ) -> Optional[Dict[str, Any]]:
        """Use a lightweight model to evaluate whether the interview should transition phases."""

        time_in_phase = state.calculate_time_in_phase(session_id)
        total_time = state.calculate_total_time(session_id)
        silence_duration = state.calculate_silence_duration(session_id)
        code_idle_duration = state.calculate_code_idle_duration(session_id)

        payload = self._build_phase_decision_payload(
            interview_state=interview_state,
            conversation=conversation,
            user_message=user_message,
            model_reply=model_reply,
            time_in_phase=time_in_phase,
            total_time=total_time,
            silence_duration=silence_duration,
            code_idle_duration=code_idle_duration,
        )

        try:
            response = requests.post(
                self.API_URL_TEMPLATE.format(model=self.phase_model),
                params={"key": self.api_key},
                json=payload,
                timeout=20,
            )
        except RequestException as exc:  # type: ignore[name-defined]
            logging.error("Phase decision request failed: %s", exc)
            return None

        if response.status_code != 200:
            logging.warning(
                "Phase decision model error: status=%s body=%s",
                response.status_code,
                response.text,
            )
            return None

        data = response.json()
        try:
            parts = data["candidates"][0]["content"]["parts"]
            decision_text = " ".join(part.get("text", "") for part in parts if "text" in part).strip()
        except (KeyError, IndexError) as exc:
            logging.warning("Phase decision payload missing text: %s", data)
            return None

        if decision_text:
            logging.info("[PHASE DECISION RAW] %s", decision_text)

        decision = self._parse_phase_decision(decision_text)
        if not decision:
            logging.warning("Unable to parse phase decision JSON: %s", decision_text)
            return None

        next_phase = decision.get("next_phase")
        if next_phase and next_phase not in {
            state.PHASE_INTRO,
            state.PHASE_RESUME,
            state.PHASE_CODING,
            state.PHASE_QUESTIONS,
        }:
            logging.warning("Phase decision returned invalid next_phase: %s", decision)
            return None

        return decision

    def _build_phase_decision_payload(
        self,
        interview_state: Dict[str, Any],
        conversation: List[Dict[str, Any]],
        user_message: str,
        model_reply: str,
        time_in_phase: float,
        total_time: float,
        silence_duration: float,
        code_idle_duration: float,
    ) -> Dict[str, Any]:
        current_phase = interview_state.get("current_phase", state.PHASE_INTRO)
        mode = interview_state.get("mode", "full")
        time_in_phase = float(time_in_phase or 0.0)
        total_time = float(total_time or 0.0)
        problem_presented = bool(interview_state.get("problem_presented", False))

        snippet = self._format_conversation_snippet(conversation)

        context = {
            "current_phase": current_phase,
            "mode": mode,
            "time_in_phase_minutes": round(time_in_phase, 2),
            "total_time_minutes": round(total_time, 2),
            "seconds_since_candidate_spoke": round(float(silence_duration or 0.0), 1),
            "seconds_since_code_change": round(float(code_idle_duration or 0.0), 1),
            "problem_already_presented": problem_presented,
            "recent_candidate_message": user_message,
            "model_reply_being_sent": model_reply,
            "conversation_excerpt": snippet,
            "phase_options": [
                state.PHASE_INTRO,
                state.PHASE_RESUME,
                state.PHASE_CODING,
                state.PHASE_QUESTIONS,
            ],
        }

        system_prompt = (
            "You are the phase coordinator for a live technical interview.\n"
            "Decide whether the interviewer should switch phases based on the conversation flow, "
            "the time spent in the current phase, and whether the candidate appears ready.\n"
            "Only recommend a transition when it feels natural and consistent with the discussion.\n"
            "If the current dialogue still fits the phase objectives, do not transition yet.\n"
            "For full mode, enforce hard timing windows: do not transition to coding before 10 minutes total, "
            "and transition to questions around 35 minutes total.\n"
            "Respond ONLY with strict JSON. Do not include any extra commentary."
        )

        instructions = (
            "Return JSON with the following keys:\n"
            '{\n'
            '  "should_transition": true | false,\n'
            '  "next_phase": "intro" | "resume" | "coding" | "questions" | null,\n'
            '  "reason": "concise explanation",\n'
            '  "confidence": number between 0 and 1,\n'
            '  "mark_problem_presented": true | false\n'
            '}\n'
            "If should_transition is false, set next_phase to null. "
            "Only set mark_problem_presented true if the coding problem was clearly introduced."
        )

        payload: Dict[str, Any] = {
            "systemInstruction": {
                "role": "system",
                "parts": [{"text": system_prompt}],
            },
            "contents": [
                {
                    "role": "user",
                    "parts": [
                        {
                            "text": instructions + "\n\nCONTEXT:\n" + json.dumps(context, ensure_ascii=False),
                        }
                    ],
                }
            ],
            "generationConfig": {
                "temperature": 0.1,
                "topP": 0.8,
                "topK": 32,
                "maxOutputTokens": 200,
            },
        }
        return payload

    def _format_conversation_snippet(
        self,
        conversation: List[Dict[str, Any]],
        max_turns: int = 8,
    ) -> str:
        if not conversation:
            return ""

        if max_turns and max_turns > 0:
            recent_turns = conversation[-max_turns:]
        else:
            recent_turns = conversation
        lines: List[str] = []
        for turn in recent_turns:
            role = turn.get("role")
            parts = turn.get("parts", [])
            text_segments = []
            for part in parts:
                if isinstance(part, dict):
                    text_segments.append(part.get("text", ""))
            text = " ".join(text_segments).strip()
            if not text:
                continue
            speaker = "Interviewer" if role == "model" else "Candidate"
            lines.append(f"{speaker}: {text}")
        return "\n".join(lines)

    def _parse_phase_decision(self, text: str) -> Optional[Dict[str, Any]]:
        if not text:
            return None
        text = text.strip()
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            match = re.search(r"\{.*\}", text, re.DOTALL)
            if not match:
                return None
            try:
                return json.loads(match.group(0))
            except json.JSONDecodeError:
                return None

    def _build_phase_prompt(
        self,
        current_phase: str,
        language: str,
        resume_text: Optional[str],
        current_code: str,
        code_changed: bool,
        problem_presented: bool,
        time_in_phase: float,
        total_time: float,
        silence_duration: float,
        code_idle_duration: float,
        mode: str = "full",
        company_context: Optional[Dict[str, str]] = None,
        ood_question: Optional[Dict[str, Any]] = None,
        coding_question: Optional[Dict[str, Any]] = None,
        code_evaluation: Optional[Dict[str, Any]] = None,
    ) -> str:
        """Build phase-specific system prompt"""

        # Base prompt - applies to all phases
        if mode == "coding_only":
            base_prompt = """You are a senior software engineer conducting a LIVE VOICE coding interview.
This is a CODING-ONLY session (35-40 minutes) - no intro, no resume discussion, just pure technical problem-solving.

üéØ SPEECH OUTPUT - THIS IS CRITICAL:
Your responses will be SPOKEN ALOUD by a text-to-speech system to the candidate.
- Think like you're having a phone conversation, not writing an email
- Write ONLY what should be spoken - no formatting, no markdown, no visual cues
- NEVER use: *, #, _, **, `, or any formatting symbols
- NEVER use filler words: "um", "uh", "hmm", "well", "so"
- Say technical terms plainly: "use a for loop" NOT "use a *for loop*"

üí¨ BE EXTREMELY CONCISE:
- DEFAULT LENGTH: 1-2 sentences (10-20 words total)
- Most responses should be under 15 words
- Only go longer (3-4 sentences) when:
  * Explaining a complex concept they specifically asked about
  * Presenting a coding problem (use [PROBLEM_START]...[PROBLEM_END] markers)
  * Giving feedback on completed solution
- If you find yourself writing more than 4 sentences, STOP and cut it down
- Every word costs time - be ruthless about brevity

üó£Ô∏è NATURAL CONVERSATION:
- Use contractions: "I'm", "you're", "that's", "let's"
- ONE thought per response - don't chain multiple ideas
- Let them speak - don't fill every silence
- Sound like a real person, not a textbook
- Vary your phrasing - avoid repetitive patterns
- Never do long step-by-step simulations or traces out loud
- If you must reference a case, summarize in 1-2 sentences

"""
        else:
            base_prompt = """You are a senior software engineer conducting a LIVE VOICE technical interview.
This is a 40-minute structured interview with natural, back-and-forth CONVERSATION.

üéØ SPEECH OUTPUT - THIS IS CRITICAL:
Your responses will be SPOKEN ALOUD by a text-to-speech system to the candidate.
- Think like you're having a phone conversation, not writing an email
- Write ONLY what should be spoken - no formatting, no markdown, no visual cues
- NEVER use: *, #, _, **, `, or any formatting symbols
- NEVER use filler words: "um", "uh", "hmm", "well", "so"
- Say technical terms plainly: "use a for loop" NOT "use a *for loop*"

üí¨ BE EXTREMELY CONCISE:
- DEFAULT LENGTH: 1-2 sentences (10-25 words total)
- Most responses should be under 20 words
- Only go longer (3-5 sentences) when:
  * Explaining a complex concept they specifically asked about
  * Presenting a coding problem (use [PROBLEM_START]...[PROBLEM_END] markers)
  * Giving detailed feedback on their work
- If you find yourself writing more than 5 sentences, STOP and cut it down
- Every word costs time - be ruthless about brevity

üó£Ô∏è NATURAL CONVERSATION:
- Use contractions: "I'm", "you're", "that's", "let's"
- ONE thought or question per response
- Let them speak - don't fill every silence
- Sound like a real person, not a textbook
- Vary your phrasing - avoid repetitive patterns
- Never do long step-by-step simulations or traces out loud
- If you must reference a case, summarize in 1-2 sentences

"""

        # Interview structure context
        if mode == "coding_only":
            structure = f"""SESSION TYPE: CODING-ONLY MODE (35-40 minutes)
You skip all intro and resume discussion. Jump STRAIGHT to presenting a coding problem.

CURRENT STATE:
- Time elapsed: {total_time:.1f} minutes
- Seconds since candidate spoke: {silence_duration:.0f}s
- Seconds since code changed: {code_idle_duration:.0f}s

"""
        else:
            structure = f"""INTERVIEW STRUCTURE (40 minutes total):
Phase 1: Intro + Resume (0-10min) - Quick rapport + background
Phase 2: Coding Problem (10-35min) - Technical assessment
Phase 3: Candidate Questions (35-40min) - Reverse interview

CURRENT STATE:
- Phase: {current_phase.upper()}
- Time in this phase: {time_in_phase:.1f} minutes
- Total interview time: {total_time:.1f} minutes
- Seconds since candidate spoke: {silence_duration:.0f}s
- Seconds since code changed: {code_idle_duration:.0f}s

"""

        company_lines: List[str] = []
        if company_context:
            company_value = (company_context.get("company") or "").strip()
            role_value = (company_context.get("role") or "").strip()
            details_value = (company_context.get("details") or "").strip()
            if company_value:
                company_lines.append(f"Company: {company_value}")
            if role_value:
                company_lines.append(f"Role: {role_value}")
            if details_value:
                company_lines.append(f"Notes: {details_value}")

        if company_lines:
            structure += "COMPANY & ROLE CONTEXT:\n" + "\n".join(f"- {line}" for line in company_lines) + "\n\n"

        # Phase-specific instructions
        if current_phase == state.PHASE_INTRO:
            phase_instructions = """INTRODUCTION PHASE:
Your first response (if just starting):
- ONE sentence intro: "Hi, I'm [Name], senior engineer at [Company]."
- ONE sentence about format: "This'll be a 40-minute interview - intro, coding, then your questions."
- ONE sentence warmup: "Sound good?" or "Ready to start?"
Total: 3 sentences max (under 30 words)

After they respond:
- Move to resume discussion: "Great. Tell me about yourself."
- Keep everything conversational and brief
- No need to explain every detail upfront

TRANSITION at 3-5 minutes total: "Let's talk about your background."
"""

        elif current_phase == state.PHASE_RESUME:
            resume_context = f"\n\nCANDIDATE'S RESUME:\n{resume_text}\n" if resume_text else "\n[No resume provided]"
            phase_instructions = f"""RESUME DISCUSSION PHASE:{resume_context}

RESPONSE STYLE:
- Ask ONE question at a time (10-15 words)
- Follow-ups should be brief: "Tell me more about that" or "What challenges did you face?"
- Listen more, talk less

QUESTIONS TO ASK (pick 3-4 total):
- Recent projects and impact
- Technical challenges they solved
- Technologies they're comfortable with
- What they're excited about

TIMING: Time in phase {time_in_phase:.1f}min | Total {total_time:.1f}min
- Target: Finish by 10 min total
- At 10 min OR after 3-4 questions: TRANSITION

TRANSITION: Include this EXACT phrase: "Let's move to coding"
Example: "Sounds great. Let's move to coding now. Ready?"
"""

        elif current_phase == state.PHASE_CODING:
            language_display = {
                "python": "Python",
                "java": "Java",
                "c": "C",
                "cpp": "C++"
            }.get(language, language)

            # Show code without markdown formatting (model should not output markdown)
            if current_code.strip():
                code_display = f"\n=== CURRENT CODE IN EDITOR ===\n{current_code}\n=== END OF CODE ===\n"
            else:
                code_display = "\n=== CURRENT CODE IN EDITOR ===\n[No code written yet]\n=== END OF CODE ===\n"

            visibility_instructions = """CODE VISIBILITY & EDITOR ACCESS:
- The snapshot between the 'CURRENT CODE IN EDITOR' markers above is EXACTLY what the candidate has typed.
- YOU CAN READ IT DIRECTLY. Never say you cannot see their code or editor.
- If it literally shows "[No code written yet]", tell the candidate their editor is empty instead of claiming you lack access.
- When code exists, reference concrete details from it (functions, variables, logic) before giving feedback.
- Some user messages also include <<CURRENT_EDITOR_SNAPSHOT>> ... <<END_CURRENT_EDITOR_SNAPSHOT>> markers. Treat those as a live view of the editor right before their utterance.
- When you need to modify their code, output a [CODE_START] ... [CODE_END] block to overwrite the editor.

"""

            evaluation_block = ""
            if code_evaluation:
                status = str(code_evaluation.get("status", "")).strip()
                summary = str(code_evaluation.get("summary", "")).strip()
                if status:
                    evaluation_block = (
                        "INTERNAL CODE EVALUATION (DO NOT MENTION TESTS OR COUNTS):\n"
                        f"- Status: {status}\n"
                    )
                    if summary:
                        evaluation_block += f"- Summary: {summary}\n"
                    evaluation_block += "Use this only to guide your feedback.\n\n"

            selected_question_block = ""
            if coding_question and coding_question.get("title"):
                title = str(coding_question.get("title", "")).strip()
                difficulty = str(coding_question.get("difficulty", "")).strip()
                acceptance = str(coding_question.get("acceptance", "")).strip()
                signature = ""
                signatures = coding_question.get("signatures") if isinstance(coding_question, dict) else None
                if isinstance(signatures, dict):
                    signature = str(signatures.get(language, "")).strip()
                details = [f"- Title: {title}"]
                if difficulty:
                    details.append(f"- Difficulty: {difficulty}")
                if acceptance:
                    details.append(f"- Acceptance: {acceptance}")
                if signature:
                    details.append(f"- Required function signature ({language_display}): {signature}")
                selected_question_block = "USE THIS QUESTION FROM THE BANK:\n" + "\n".join(details) + "\nDo NOT choose another question.\n\n"

            if not problem_presented:
                # Different instructions for coding_only mode
                if mode == "coding_only":
                    phase_instructions = f"""CODING-ONLY MODE - PRESENT PROBLEM IMMEDIATELY:

LANGUAGE: {language_display}
{code_display}{visibility_instructions}{evaluation_block}
{selected_question_block}

WHEN CANDIDATE GREETS YOU:
1. Brief greeting: "Hi! Ready for a coding problem?"
2. Present problem in [PROBLEM_START]...[PROBLEM_END] markers
   - Use the selected question above (if provided)
   - Difficulty: MEDIUM preferred when the bank does not specify
   - Include the required function signature verbatim
   - Ensure the problem statement and examples use ONLY the types from the required signature
   - Include examples in the markers
3. Outside markers, keep spoken text under 15 words: "Take a minute to think about your approach."
4. Ask: "Any questions on the problem?"

AFTER THEY UNDERSTAND:
- Guide approach discussion BEFORE coding
- Short prompts: "What's your approach?" "What about edge cases?" "Time complexity?"

WRITING CODE TO EDITOR:
Only write code if: (1) Time almost up, OR (2) They're stuck and explicitly ask
Format: "Let me show you. [CODE_START]...code...[CODE_END] This uses a HashMap."
Otherwise: Give hints, not solutions

DEFAULT: 1-2 sentence responses. Let them work."""
                else:
                    phase_instructions = f"""CODING PHASE - PROBLEM PRESENTATION STAGE:

LANGUAGE: {language_display}
{code_display}{visibility_instructions}{evaluation_block}
{selected_question_block}

YOUR TASK NOW:
1. Use the selected question above if provided
   - If none is provided, select a LeetCode-style problem from your knowledge
   - Difficulty: MEDIUM-HARD preferred, or EASY with MEDIUM-HARD follow-ups
   - Choose a problem that reasonably takes ~25 minutes to solve with discussion
   - Pick something relevant to their resume/experience if possible

2. Present the problem inside [PROBLEM_START]...[PROBLEM_END] markers:
   - State the problem naturally (don't just copy-paste)
   - Give example inputs/outputs
   - Ask if they have clarifying questions
   - Include the required function signature verbatim
   - Ensure the problem statement and examples use ONLY the types from the required signature
   - Do not read the examples out loud; keep spoken text brief outside the markers

3. GUIDE THEM TO DISCUSS APPROACH FIRST:
   - Don't let them jump to coding immediately
   - Make them explain their approach
   - Ask about edge cases
   - Discuss time/space complexity

CODE WRITING CAPABILITY:
- You MUST avoid giving full solutions early. Be an interviewer, not a tutor.
- Only provide hints and guiding questions unless time is nearly up.
- You MAY write code directly to the candidate's editor ONLY when:
  1. Time is almost up and they have not solved it, OR
  2. They are truly stuck after multiple hints and explicitly ask for the solution.
- If they ask you to write code early, refuse politely and offer a hint instead.
- CRITICAL: Before writing code, ALWAYS look at what they already have
- You can modify their existing code or provide a complete replacement
- To write code to the editor, you MUST use this EXACT format:
  1. First, say what you're doing (e.g., "Let me write that for you")
  2. Then add the code block with these EXACT markers:

  [CODE_START]
  your complete code here
  [CODE_END]

  3. Then optionally explain what you wrote
- Example response when asked to write code:
  "Okay, let me write a solution for you. [CODE_START]
  def two_sum(nums, target):
      seen = {{}}
      for i, num in enumerate(nums):
          if target - num in seen:
              return [seen[target - num], i]
          seen[num] = i
  [CODE_END] This solution uses a hash map for O(n) time complexity."
- The code between markers will replace ALL content in the editor
- IMPORTANT: Only use this when truly necessary - let them code themselves!

REMEMBER: After presenting, I will mark problem as presented."""

            else:
                phase_instructions = f"""CODING PHASE - ACTIVE SOLVING:

LANGUAGE: {language_display}
{code_display}{visibility_instructions}{evaluation_block}

RESPONSE GUIDE (choose based on situation):

IF they just spoke:
- Answer their question (1-2 sentences)
- Provide hints if stuck (don't give solutions)
- Example: "What if you use a HashMap?" or "Consider the edge case when the array is empty."

IF they're actively coding (code changed recently):
- Stay quiet! Let them work
- Check-in every 2-3 min: "How's it going?"

IF they're stuck (silence >{silence_duration:.0f}s, no code >{code_idle_duration:.0f}s):
- Offer help: "What are you thinking?" or "What's blocking you?"
- Guide with questions, not answers

IF reviewing their code:
- Look at the actual code above
- Be specific: "I see you're using a nested loop. Can we optimize that?"
- Discuss: edge cases, complexity, bugs

WRITING CODE:
Only if: time almost up OR they're stuck and ask for solution
Format: "Let me show you. [CODE_START]...code...[CODE_END] This is O(n) time."

TIME: {time_in_phase:.1f}min in phase, {total_time:.1f}min total
At ~25min in phase: "Let's start wrapping up."
At ~35min total: "Nice work. What questions do you have for me?"
"""

        elif current_phase == state.PHASE_QUESTIONS:
            phase_instructions = f"""QUESTIONS PHASE - THEIR TURN:

ROLE: Answer their questions about the company/role/team

STYLE:
- Keep answers conversational and genuine (2-3 sentences each)
- Make up reasonable details about team, tech stack, culture
- Be helpful and encouraging

OPENING: "What questions do you have for me?"

CLOSING (at ~40 min total):
"Thanks for your time today. We'll be in touch soon. Best of luck!"

TIME: {time_in_phase:.1f}min in phase
"""

        elif current_phase == state.PHASE_OOD_DESIGN:
            language_display = {
                "python": "Python",
                "java": "Java",
                "c": "C",
                "cpp": "C++"
            }.get(language, language)

            if current_code.strip():
                code_display = f"\n=== CURRENT CODE / NOTES IN EDITOR ===\n{current_code}\n=== END OF EDITOR ===\n"
            else:
                code_display = "\n=== CURRENT CODE / NOTES IN EDITOR ===\n[Editor is currently empty]\n=== END OF EDITOR ===\n"

            company_label = "the target company/role"
            if company_context:
                company_label = (company_context.get("company") or company_context.get("role") or company_label)

            question_details = ""
            if ood_question:
                title = (ood_question.get("title") or "").strip()
                description = (ood_question.get("description") or "").strip()
                if title or description:
                    special_note = ""
                    lowered_title = title.lower()
                    if "stock" in lowered_title and "match" in lowered_title:
                        special_note = (
                            "- This is THE STOCK EXCHANGE MATCHING ENGINE scenario. Drill relentlessly into limit order book structures, price-time priority enforcement, failover plans, and latency/risk tradeoffs.\n"
                            "- Make the candidate justify data structures, concurrency control, and recovery testing in detail.\n"
                        )
                    question_details = f"""COMPANY-ALIGNED PROBLEM TO USE:
- Title: {title or 'Use your best judgment'}
- Description: {description or 'Frame a scenario inspired by the company context.'}
- Tie this scenario directly to {company_label} so it feels relevant.
{special_note}

"""

            phase_instructions = f"""OBJECT-ORIENTED DESIGN PHASE - DESIGN DISCUSSION (20 minutes):

LANGUAGE: {language_display}
{code_display}
TIME MANAGEMENT:
- Total OOD interview: 40 minutes
- Design phase: 20 minutes (current time: {time_in_phase:.1f} minutes)
- Implementation phase: 20 minutes (auto-transition at 20 min mark)

YOUR ROLE - STRICT AND CHALLENGING:
You are a SENIOR ARCHITECT conducting a rigorous OOD interview. Be SMART, STRICT, and CRITICAL.

PRESENTATION (First interaction only):
When the candidate greets you, present the OOD problem clearly and concisely. State the problem, basic requirements, and ask them to start designing.

DURING DESIGN DISCUSSION:
- The candidate should be LEADING the design - YOU are evaluating, not guiding
- Challenge their decisions. Ask "why?" frequently
- Point out flaws, edge cases, and missed requirements
- Keep responses concise (1-3 sentences) unless they ask for detail
- Test their knowledge of:
  * SOLID principles
  * Design patterns (when applicable)
  * Object relationships (composition vs inheritance)
  * Encapsulation and abstraction
  * Scalability and extensibility

STRICT INTERVIEWING STYLE:
- Do NOT provide hints unless they are completely stuck for 1+ minute
- Do NOT guide them step-by-step - let them struggle and think
- Ask probing questions:
  * "How would this handle X scenario?"
  * "What if requirements changed to Y?"
  * "Why did you choose composition over inheritance here?"
  * "How does this follow the Single Responsibility Principle?"
- If they make a poor design choice, don't immediately correct them - ask questions to make them realize it
- Be skeptical of their explanations - make them justify decisions

RESPONSE STYLE:
- Short questions to probe: "Why that choice?" "What about scalability?"
- Challenge poor decisions: "That'll be slow. What's better?"
- Don't praise mediocre work - be honest
- 1-2 sentences unless deep technical discussion

EDITOR:
- They use editor for sketching classes/relationships
- Always read what's there before responding
- If empty: "The editor's empty. Sketch your main classes."
- Reference what you see: "I see UserService. How does it interact with the cache?"

WRITING TO EDITOR:
Use [CODE_START]...design...[CODE_END] only when needed
Keep it minimal - let them drive

{question_details}TRANSITION at ~18-20min:
"Let's move to implementing your design. You have 20 minutes."

Be tough but fair. This is a HARD interview."""

        elif current_phase == state.PHASE_OOD_IMPLEMENTATION:
            language_display = {
                "python": "Python",
                "java": "Java",
                "c": "C",
                "cpp": "C++"
            }.get(language, language)

            # Show code without markdown formatting (model should not output markdown)
            if current_code.strip():
                code_display = f"\n=== CURRENT CODE IN EDITOR ===\n{current_code}\n=== END OF CODE ===\n"
            else:
                code_display = "\n=== CURRENT CODE IN EDITOR ===\n[No code written yet]\n=== END OF CODE ===\n"

            company_label = "the target company/role"
            if company_context:
                company_label = (company_context.get("company") or company_context.get("role") or company_label)
            question_title = ""
            if ood_question:
                question_title = (ood_question.get("title") or "").strip()
            question_reminder = f"Keep referencing how this implementation solves {question_title or 'the company-aligned problem'} for {company_label}." if question_title or company_context else "Tie every implementation decision back to the scenario you outlined."
            extra_impl_emphasis = ""
            lowered_title = question_title.lower()
            if "stock" in lowered_title and "match" in lowered_title:
                extra_impl_emphasis = (
                    "- FORCE the candidate to model bids/asks, price-time priority queues, partial fills, and cancel/replace logic in code.\n"
                    "- Challenge them on throughput (millions of orders/sec), determinism, and how they'd simulate the engine for correctness + latency testing.\n"
                )

            phase_instructions = f"""OBJECT-ORIENTED DESIGN PHASE - IMPLEMENTATION (20 minutes):

LANGUAGE: {language_display}
{code_display}

TIME MANAGEMENT:
- Design phase complete (spent ~20 minutes)
- Implementation phase: 20 minutes (current time: {time_in_phase:.1f} minutes)
- Total time: {total_time:.1f} minutes

YOUR ROLE - CODE REVIEW AND CRITIQUE:
The candidate is now implementing the design they created. Continue being STRICT and CRITICAL.

IMPLEMENTATION REVIEW:
- Let them code without interrupting
- When they pause, review critically (1-2 sentences):
  * "Why is this field public?"
  * "This method does too much. What principle does that violate?"
  * "Where's the abstraction for X?"
- Look for: encapsulation, SOLID principles, clean code, {question_reminder}
{extra_impl_emphasis}
EDITOR: Reference what you see - "In the editor I see..."

RESPONSE LENGTH: 1-2 sentences unless detailed technical discussion

CODE WRITING CAPABILITY (Use sparingly):
- You CAN write code to the editor if absolutely necessary
- ONLY write code when:
  1. Candidate explicitly asks you to show something
  2. Time is almost up and you need to show correct structure
  3. Candidate is hopelessly stuck on syntax (rare)
- To write code, use this format:
  [CODE_START]
  your code here
  [CODE_END]
- IMPORTANT: Let them code themselves - this is THEIR interview

IF THEY'RE STUCK:
- Don't immediately help - see if they can figure it out
- Ask guiding questions rather than giving answers
- If stuck for 1+ minute on something trivial, provide a small hint

WRAPPING UP:
At ~38-40 minutes total (18-20 minutes in implementation):
"We're out of time. Let's review what you've built. Walk me through your code."
Then provide critical feedback on their implementation, highlighting both strengths and major weaknesses.

Remember: Be HONEST about code quality. Don't praise poor code."""

        else:
            phase_instructions = "Unknown phase - continue interview naturally."

        # Add examples of good vs bad responses
        response_examples = """
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
RESPONSE EXAMPLES (CRITICAL - FOLLOW THESE PATTERNS):
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

SCENARIO: Candidate asks about time complexity

‚ùå BAD (66 words, written style):
"So, the time complexity of your current solution is actually O(n squared) because you have a nested loop structure. The outer loop iterates through all n elements, and for each element, the inner loop also potentially iterates through all n elements. This is generally not ideal for large inputs, and you might want to consider if there's a way to optimize this."

‚úÖ GOOD (12 words, conversational):
"That's O(n squared) because of the nested loops. Can you optimize it?"

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

SCENARIO: Candidate explains their approach

‚ùå BAD (78 words, over-explaining):
"Okay, I understand your approach now. So basically what you're saying is that you want to use a hash map to store the values that you've already seen, and then as you iterate through the array, you'll check if the complement exists in the hash map. That makes sense. This is actually a very common and efficient approach to this problem. The time complexity would be O(n) and the space complexity would also be O(n). Before we move on to coding, let me ask you about edge cases."

‚úÖ GOOD (4 words):
"Got it. Edge cases?"

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

SCENARIO: Candidate stuck and silent for 40 seconds

‚ùå BAD (62 words, too many options):
"I notice you've been quiet for a bit. Are you stuck on something? If you're having trouble figuring out the optimal data structure, maybe think about what operations you need to be fast. Do you need fast lookups? Fast insertions? Or maybe you should think about the problem differently - have you considered a two-pointer approach instead?"

‚úÖ GOOD (7 words):
"What are you thinking? Where are you stuck?"

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

SCENARIO: Candidate asks if their code is correct

‚ùå BAD (72 words, avoiding answer):
"Well, that's an interesting question. Let me think about this for a moment. So looking at your code, I can see that you've implemented the basic logic, and the general structure looks okay, but there might be a few issues that we should discuss. For example, I'm not entirely sure about the edge case handling. What happens when the array is empty? Have you considered that scenario?"

‚úÖ GOOD (9 words):
"Walk me through what happens when the array is empty."

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

SCENARIO: Reviewing completed solution

‚ùå BAD (85 words, excessive praise):
"Excellent work! This is a really solid solution. I'm impressed with how you approached this problem. The use of the hash map is perfect here, and your code is very clean and readable. The variable names are descriptive, the logic is easy to follow, and you've handled the edge cases well. This is definitely the kind of solution we'd expect from a strong candidate. The time complexity is optimal at O(n), and the space complexity trade-off is totally reasonable."

‚úÖ GOOD (8 words):
"Looks good. What's the space complexity and why?"

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

KEY RULES YOU MUST FOLLOW:
‚Ä¢ Target: 10-20 words per response (under 15 is ideal)
‚Ä¢ Direct and conversational
‚Ä¢ ONE thought per response
‚Ä¢ Ask questions instead of explaining
‚Ä¢ No filler, no repetition
‚Ä¢ Sound like a phone conversation
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
"""

        return base_prompt + structure + phase_instructions + response_examples

    def _normalize_editor_code(self, code: Optional[str]) -> str:
        """Normalize editor snapshot so placeholders don't appear as real code."""
        if not code:
            return ""

        stripped = code.strip()
        placeholder_markers = {
            "// Start coding here...",
            "# Start coding here...",
            "/* Start coding here... */",
            "Start coding here...",
            "# Use this editor for design notes, pseudocode, and implementation.",
            "// Use this editor for design notes, pseudocode, and implementation.",
        }
        if stripped in placeholder_markers:
            return ""
        return code

    def _build_user_payload_with_editor_context(
        self,
        user_message: str,
        normalized_code: str,
    ) -> str:
        """Embed editor context alongside the candidate's utterance for the model."""
        segments: List[str] = []

        snapshot = normalized_code.strip() or "[Editor is currently empty]"
        segments.append(
            "<<CURRENT_EDITOR_SNAPSHOT>>\n"
            f"{snapshot}\n"
            "<<END_CURRENT_EDITOR_SNAPSHOT>>"
        )

        segments.append(
            "<<CANDIDATE_UTTERANCE>>\n"
            f"{user_message}\n"
            "<<END_CANDIDATE_UTTERANCE>>"
        )
        return "\n\n".join(segments)
